# ISL Dataset Training Guide

This guide explains how to train a custom Indian Sign Language model using your local dataset and integrate it with Sign & Speak.

## ğŸ“‹ Overview

The current system uses **rule-based gesture recognition**. We'll add a **machine learning model** trained on your ISL dataset to improve accuracy for Indian Sign Language.

## ğŸ¯ Architecture

```
Your ISL Dataset â†’ Training Script â†’ TensorFlow.js Model â†’ Sign & Speak App
```

## ğŸ“ Expected Dataset Structure

Your ISL dataset should be organized like this:

```
ISL_Dataset/
â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ B/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ C/
â””â”€â”€ ... (for each character/sign)
```

Or with MediaPipe landmark data:
```
ISL_Dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ A.json    # Array of landmark coordinates
â”‚   â”œâ”€â”€ B.json
â”‚   â””â”€â”€ ...
â””â”€â”€ test/
    â”œâ”€â”€ A.json
    â””â”€â”€ ...
```

## ğŸš€ Setup Instructions

### Step 1: Install Python Dependencies

Create a Python environment for training:

```bash
# Create virtual environment
python -m venv isl_env

# Activate (Windows)
isl_env\Scripts\activate

# Install dependencies
pip install tensorflow opencv-python mediapipe numpy pillow scikit-learn matplotlib
```

### Step 2: Prepare Training Script

I'll create a Python script that:
1. Loads your ISL dataset
2. Extracts MediaPipe hand landmarks from images
3. Trains a neural network
4. Exports to TensorFlow.js format

### Step 3: Place Your Dataset

Copy your ISL dataset to:
```
Sign-and-Speak/
â””â”€â”€ ml_training/
    â””â”€â”€ isl_dataset/
        â”œâ”€â”€ A/
        â”œâ”€â”€ B/
        â””â”€â”€ ...
```

## ğŸ“ Training Options

### Option 1: Image-Based Training (Recommended)
- Uses your ISL images directly
- Extracts MediaPipe landmarks automatically
- Works with existing dataset structure

### Option 2: Landmark-Based Training (Faster)
- Pre-extracted landmark coordinates
- Faster training
- Requires preprocessing

### Option 3: Transfer Learning
- Fine-tune existing model
- Requires less data
- Better for small datasets

## ğŸ“Š Model Architecture

We'll use a simple but effective architecture:

```python
Input: 21 landmarks Ã— 3 coordinates (x, y, z) = 63 features
â†“
Dense(128) + ReLU + Dropout(0.3)
â†“
Dense(64) + ReLU + Dropout(0.3)
â†“
Dense(num_classes) + Softmax
â†“
Output: Probability for each ISL character
```

## ğŸ”§ Integration Steps

1. **Train the model** using the provided script
2. **Convert to TensorFlow.js** format
3. **Copy model files** to `webapp/public/models/`
4. **Update CameraPanel.jsx** to use the trained model
5. **Test** with real-time camera input

## ğŸ“ Next Steps

Let me know:
1. What format is your ISL dataset in? (images, videos, landmarks)
2. How many signs/characters does it contain?
3. What's the approximate size of the dataset?

I'll then create the specific training script and integration code for your setup!
